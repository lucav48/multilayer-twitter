{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707daa38",
   "metadata": {},
   "source": [
    "## LOAD LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import networkx as nx\n",
    "import tweepy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import string\n",
    "import powerlaw\n",
    "import math\n",
    "import statistics\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\")\n",
    "base_path = \"network/\"\n",
    "\n",
    "def graph_statistics(graph, need_plot=True):\n",
    "    print(\"NODES:\", len(graph.nodes))\n",
    "    print(\"EDGES:\", len(graph.edges))\n",
    "    print(\"DENSITY: {:0.2}\".format(nx.density(graph)))\n",
    "    print(\"CONNECTED COMPONENTS:\", nx.number_connected_components(graph))\n",
    "    print(\"MAX CONNECTED COMPONENTS: \", max([len(x) for x in nx.connected_components(graph)]))\n",
    "    print(\"CLUSTERING: {:0.2}\".format(nx.average_clustering(graph)))\n",
    "    print(\"MEAN WEIGHT: {:0.2}\".format(sum([x[2][\"weight\"] for x in graph.edges(data=True)]) / len(graph.edges)))\n",
    "    if need_plot:\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.title(\"CONNECTED COMPONENT DIMENSIONS\")\n",
    "        sns.histplot([len(x) for x in nx.connected_components(graph)], bins=100)\n",
    "    \n",
    "def centrality(graph, k=10, adjust=False, title=\"\"):\n",
    "    degree = {k: graph.degree(k) for k in graph.nodes}\n",
    "    degree = {k: v for k, v in sorted(degree.items(), key=lambda item: item[1], reverse=True)}\n",
    "    print(\"TOP USERS BY DEGREE\")\n",
    "    top_degree = list(degree.keys())[:k]\n",
    "#     print(top_degree)\n",
    "        \n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    fig = format_graph(fig, x_label=\"Degree centrality\", title=title)\n",
    "    dis = np.histogram(list(degree.values()), bins=max(list(degree.values())))\n",
    "    dis = dict(zip(dis[1], dis[0] + 1))\n",
    "    dis = {k: v for k, v in sorted(dis.items(), key=lambda item: item[1], reverse=True) if k > 0}\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    sns.scatterplot(x = dis.keys(), y = dis.values())\n",
    "    plt.xscale('symlog')\n",
    "    plt.yscale('symlog')\n",
    "\n",
    "    print(\"DEGREE CENTRALITY POWER LAW\")\n",
    "    results = powerlaw.Fit(np.histogram(list(degree.values()), bins=50)[0])\n",
    "    print(\"Alpha: \", str(results.power_law.alpha), \" Delta: \", str(results.power_law.D))\n",
    "    return top_degree\n",
    "\n",
    "def format_graph(fig, x_label, title=\"\"):\n",
    "    ax = fig.gca()\n",
    "    ax.set_xlabel(x_label, fontsize=21)\n",
    "    ax.set_ylabel(\"Number of users\", fontsize=21)\n",
    "    ax.set_title(title, fontsize=24)\n",
    "    return fig\n",
    "\n",
    "def ego(graph, nodes):\n",
    "    # print(\"EGO ANALYSIS ON\", nodes)\n",
    "    density = 0\n",
    "    clustering = 0\n",
    "    for n in nodes:\n",
    "      try:\n",
    "        e = nx.ego_graph(graph, n)\n",
    "        c = nx.average_clustering(e)\n",
    "        d = nx.density(e)\n",
    "        density += d\n",
    "        clustering += c\n",
    "        print(n, \"nodes\", len(e.nodes), \"density\", round(d, 3), \"clustering\", round(c, 3))\n",
    "      except:\n",
    "        print(n, \"not present\")\n",
    "    return {\"mean_density\": round(density / len(nodes), 3), \n",
    "            \"mean_clustering\": round(clustering / len(nodes), 3)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ed947",
   "metadata": {},
   "source": [
    "## LOAD GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_graph = nx.read_gexf(base_path + \"retweet.gexf\")\n",
    "reply_graph = nx.read_gexf(base_path + \"reply_to.gexf\")\n",
    "edges_list = pd.read_csv(base_path + \"network_likes.csv\", sep=\";\").apply(lambda x: \n",
    "                                                                         str(x[0]) + \" \" + str(x[1]) + \" {'weight': \" + str(x[2]) + \"}\", axis=1)\n",
    "likes_graph = nx.parse_edgelist(edges_list)\n",
    "edges_list = pd.read_csv(base_path + \"network_mentions.csv\", sep=\";\").apply(lambda x: \n",
    "                                                                         str(x[0]) + \" \" + str(x[1]) + \" {'weight': \" + str(x[2]) + \"}\", axis=1)\n",
    "mentions_graph = nx.parse_edgelist(edges_list)\n",
    "\n",
    "retweet_graph.remove_edges_from(nx.selfloop_edges(retweet_graph))\n",
    "reply_graph.remove_edges_from(nx.selfloop_edges(reply_graph))\n",
    "likes_graph.remove_edges_from(nx.selfloop_edges(likes_graph))\n",
    "mentions_graph.remove_edges_from(nx.selfloop_edges(mentions_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347498c3",
   "metadata": {},
   "source": [
    "# SINGLE LAYER ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46792219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top users to select\n",
    "top_k = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a730d",
   "metadata": {},
   "source": [
    "## RETWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397bd6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_statistics(retweet_graph, need_plot=False)\n",
    "retweet_degree = centrality(retweet_graph, k = top_k, title=\"RETWEET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed31abcc",
   "metadata": {},
   "source": [
    "## REPLY TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7100d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_statistics(reply_graph, need_plot=False)\n",
    "replyto_degree =centrality(reply_graph, k = top_k,title=\"REPLY TO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89a0ac",
   "metadata": {},
   "source": [
    "## LIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc69bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_statistics(likes_graph, need_plot=False)\n",
    "likes_degree =centrality(likes_graph, k = top_k, adjust=True,title=\"LIKE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e6a24f",
   "metadata": {},
   "source": [
    "## MENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79863ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_statistics(mentions_graph, need_plot=False)\n",
    "mentions_degree =centrality(mentions_graph, k = top_k, adjust=True,title=\"MENTION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e4e6fe",
   "metadata": {},
   "source": [
    "## INTERSECTION BY CENTRALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without like relationship\n",
    "top_users_nolike= set(retweet_degree).intersection(replyto_degree).intersection(mentions_degree)\n",
    "len(top_users_nolike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e934d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with like relationship\n",
    "top_users_like= set(retweet_degree).intersection(replyto_degree).intersection(mentions_degree).intersection(likes_degree)\n",
    "len(top_users_like)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8516e394",
   "metadata": {},
   "source": [
    "## EGO NETWORK ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ego(graph, nodes, graph_title):\n",
    "    print(\"EGO ANALYSIS ON\", graph_title)\n",
    "    user = {}\n",
    "    overlap = {}\n",
    "    for n in nodes:\n",
    "        try:\n",
    "            e = nx.ego_graph(graph, n)\n",
    "            c = nx.average_clustering(e)\n",
    "            d = nx.density(e)\n",
    "            overlap[n] = (len(set(e.nodes).intersection(nodes)) - 1) / len(nodes) \n",
    "            user[n] = {\"density\": d, \"clustering\": c, \"n_nodes\": len(e.nodes)}\n",
    "        except Exception as e:\n",
    "            user[n] = {\"density\": 0, \"clustering\": 0, \"n_nodes\": 0}\n",
    "            overlap[n] = 0\n",
    "            \n",
    "    # density and clustering plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    df = pd.DataFrame(user).T\n",
    "    sns.histplot(x=\"density\", y=\"clustering\", data=df, label=\"Verified user\",\n",
    "                    color=\"cornflowerblue\", bins=30, cbar=True, cbar_kws=dict(shrink=.75, label=\"Number of users\"))\n",
    "    ax = fig.gca()\n",
    "    ax.set_title(graph_title, fontsize=24)\n",
    "    plt.xticks(rotation=45, fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    ax.set_xlabel(\"Density\", fontsize=21)\n",
    "    ax.set_ylabel(\"Clustering coefficient\", fontsize=21)\n",
    "    ax.set_xlim((-0.05, 1.05))\n",
    "    ax.set_ylim((-0.05, 1.05))\n",
    "    \n",
    "    print(df.describe()[[\"density\", \"clustering\", \"n_nodes\"]].iloc[1:3])\n",
    "\n",
    "\n",
    "ego_users = top_users_nolike\n",
    " \n",
    "ego(retweet_graph, ego_users, \"RETWEET\")\n",
    "ego(reply_graph, ego_users, \"REPLY TO\")\n",
    "ego(likes_graph, ego_users, \"LIKE\")\n",
    "ego(mentions_graph, ego_users, \"MENTION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabba153",
   "metadata": {},
   "source": [
    "# MULTILAYER APPROACH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51892fe7",
   "metadata": {},
   "source": [
    "### USER MULTILAYER DEGREE AND TOP PLAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8312619",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_degree = {}\n",
    "graphs = [retweet_graph, reply_graph, likes_graph, mentions_graph]\n",
    "all_users = set(retweet_graph.nodes).union(reply_graph.nodes).union(likes_graph.nodes).union(mentions_graph.nodes)\n",
    "centralities = {\n",
    "          \"retweet\": {k: retweet_graph.degree(k) for k in retweet_graph.nodes},\n",
    "          \"replyto\": {k: reply_graph.degree(k) for k in reply_graph.nodes},\n",
    "          \"like\":{k: likes_graph.degree(k) for k in likes_graph.nodes},\n",
    "          \"mention\": {k: mentions_graph.degree(k) for k in mentions_graph.nodes}\n",
    "        }\n",
    "\n",
    "ego_multilayer = {}\n",
    "for user in all_users:\n",
    "  if user:\n",
    "    multi_degree[user] = []\n",
    "    for c in centralities:\n",
    "      if user in centralities[c]:\n",
    "        multi_degree[user].append(centralities[c][user])\n",
    "      else:\n",
    "        multi_degree[user].append(0)\n",
    "    multi_degree[user] = statistics.mean(multi_degree[user])\n",
    "    # multilayer ego\n",
    "    ego_net = nx.Graph()\n",
    "    for g in graphs:\n",
    "      if user in list(g.nodes):\n",
    "        other_ego = nx.ego_graph(g, user)\n",
    "        ego_net = nx.compose(ego_net, other_ego)\n",
    "        ego_net.remove_nodes_from(list(nx.isolates(ego_net)))\n",
    "        # print(len(ego_net.nodes), len(ego_net.edges), \n",
    "        #       len(other_ego.nodes), len(other_ego.edges))\n",
    "    ego_multilayer[user] = ego_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5081a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract multilayer top users\n",
    "multi_top = {k: v for k, v in sorted(multi_degree.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(len(set(list(multi_top.keys())[:67]).intersection(top_users_like)))\n",
    "print(len(set(list(multi_top.keys())[:143]).intersection(top_users_nolike)))\n",
    "multi_top_143 = list(multi_top.keys())[:143]\n",
    "multi_top_67 = list(multi_top.keys())[:67]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a3c3bb",
   "metadata": {},
   "source": [
    "## PLOT THE MULTILAYER NETWORK CENTRALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8691ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = powerlaw.Fit(list(multi_degree.values()))\n",
    "print(\"DEGREE CENTRALITY POWER LAW\")\n",
    "print(\"Alpha: \", str(results.power_law.alpha), \" Delta: \", str(results.power_law.D))\n",
    "\n",
    "\n",
    "dis = np.histogram(list(multi_degree.values()), bins=max(list(multi_degree.values())))\n",
    "dis = dict(zip(dis[1], dis[0]))\n",
    "dis = {k: v for k, v in sorted(dis.items(), key=lambda item: item[1], reverse=True) if k > 0}\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.xscale('symlog')\n",
    "plt.yscale('symlog')\n",
    "sns.scatterplot(x = dis.keys(), y = dis.values())\n",
    "plt.title(\"MULTILAYER DEGREE CENTRALITY\", fontsize=24)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlabel(\"Degree centrality\", fontsize=18)\n",
    "plt.ylabel(\"Number of users\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f152ab62",
   "metadata": {},
   "source": [
    "## EGO MULTILAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1\n",
    "info = []\n",
    "for user in multi_top_143:\n",
    "  if len(ego_multilayer[user].nodes) > threshold:  \n",
    "    weights = ego_multilayer[user].edges(data=True)\n",
    "    weights = [x[2][\"weight\"] for x in weights]\n",
    "    info.append([\n",
    "              #  nx.density(ego_multilayer[user]),\n",
    "              #  nx.average_clustering(ego_multilayer[user]),\n",
    "              len(ego_multilayer[user].nodes),\n",
    "              len(ego_multilayer[user].edges),\n",
    "              sum(weights)\n",
    "    ])\n",
    "\n",
    "stat_multi = pd.DataFrame(info, columns=[\"nodes\", \"edges\", \"interactions\"])\n",
    "stat_multi[\"label\"] = \"Multilayer Network\"\n",
    "print(stat_multi.describe().round(2))\n",
    "\n",
    "\n",
    "info = []\n",
    "for user in top_users_nolike:\n",
    "  if len(ego_multilayer[user].nodes) > threshold:\n",
    "    weights = ego_multilayer[user].edges(data=True)\n",
    "    weights = [x[2][\"weight\"] for x in weights]\n",
    "    info.append([\n",
    "              #  nx.density(ego_multilayer[user]),\n",
    "              #  nx.average_clustering(ego_multilayer[user]),\n",
    "              len(ego_multilayer[user].nodes),\n",
    "              len(ego_multilayer[user].edges),\n",
    "              sum(weights)\n",
    "    ])\n",
    "stat_single = pd.DataFrame(info, columns=[\"nodes\", \"edges\", \"interactions\"])\n",
    "stat_single[\"label\"] = \"Single Layer Network\"\n",
    "\n",
    "print(stat_single.describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ddce4b",
   "metadata": {},
   "source": [
    "## ANALYZE TOPICS DISCUSSED BY TOP USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b065c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashtag by classes (you can see some examples)\n",
    "novax = {'billgatesvaccine', 'medicalfascism', 'covidiots', 'vaccinefraud', 'notosavinglives', 'antivacc', 'nomandatoryvacccines', 'billgatesbioterror', 'coronavirusfrauds', 'antivaxxers', 'billgatesbioterrorist', 'antivaccine', 'novaccinemandates', 'covidvaccinefails', 'freedomoverfear', 'novaccineforme', 'antivax', 'notovaccines', 'masksdontwork', 'vaccinefailure', 'notomaskwashdistance', 'exposebillgates', 'researchanddestroy', 'freedomfrommedicaltyranny', 'bigpharma', 'unvaccinated', 'novaccine', 'exposebillgate'}\n",
    "neural = {'coronavirusupdates', 'vaccines', 'corona', 'covi', 'covid19pandemic', 'coronavirusvaccine', 'covid', 'covidvaccine', 'lockdown2021', 'covidrules', 'astrazeneca', 'covidsecondwave', 'vaccination', 'covid19vaccine', 'coronav', 'coronaviruswales', 'covid19', 'coronavirus', 'covidrelief', 'vaccine', 'hospital', 'covidlife', 'immune', 'variantsofconcern', 'coronavaccine', 'covid19vaccination', 'covid_19'}\n",
    "provax = {'vaccinessavelives', 'vaxxing', 'igotmyshot', 'vaccineswork', 'vaxxednow', 'vaxxed', 'wearmaskprotectlife', 'vaxxie', 'vaccinated', 'maskuptx', 'vaccinationrules', 'phuckcovid', 'vaccinateeducatorsnow', 'getvaccinated', 'indiafightscorona', 'vaccineequity', 'vaccinateny', 'wearamask', 'maskup'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6178ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = json.load(open(\"dataset/verified_tweets.txt\", \"r\"))\n",
    "df = pd.DataFrame.from_records(tweets)\n",
    "df[\"screen_name\"] = df[\"user\"].apply(lambda x: x[\"screen_name\"])\n",
    "df[\"hashtags\"] = df[\"entities\"].apply(lambda x: [y[\"text\"] for y in x[\"hashtags\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ecea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_top_keywords = {}\n",
    "single_top_keywords = {}\n",
    "\n",
    "for user in top_users_nolike:\n",
    "    user_tweets = df.loc[df[\"screen_name\"] == user].full_text.values\n",
    "    words = [x.split(\" \") for x in user_tweets]\n",
    "    words = [y.translate(str.maketrans('', '', string.punctuation)).lower() for x in words for y in x]\n",
    "    # words = [y.lower() for x in df.loc[df[\"screen_name\"] == user][\"hashtags\"].to_list() for y in x]\n",
    "    single_top_keywords[user] = {\"pro-vax\": len(set(words).intersection(provax)),\n",
    "                    \"anti-vax\": len(set(words).intersection(novax)),\n",
    "                    \"neutral\": len(set(words).intersection(neutral))}\n",
    "single_top_keywords = pd.DataFrame(single_top_keywords).T\n",
    "single_top_keywords[\"label\"] = \"Single Networks\"\n",
    "\n",
    "for user in multi_top_143:\n",
    "    user_tweets = df.loc[df[\"screen_name\"] == user].full_text.values\n",
    "    words = [x.split(\" \") for x in user_tweets]\n",
    "    words = [y.translate(str.maketrans('', '', string.punctuation)).lower() for x in words for y in x]\n",
    "    # words = [y.lower() for x in df.loc[df[\"screen_name\"] == user][\"hashtags\"].to_list() for y in x]\n",
    "    multi_top_keywords[user] = {\"pro-vax\": len(set(words).intersection(provax)),\n",
    "                    \"anti-vax\": len(set(words).intersection(novax)),\n",
    "                    \"neutral\": len(set(words).intersection(neutral))}\n",
    "multi_top_keywords = pd.DataFrame(multi_top_keywords).T\n",
    "multi_top_keywords[\"label\"] = \"Multilayer Network\"\n",
    "keywords = pd.concat([multi_top_keywords, single_top_keywords]).groupby(\"label\").sum().reset_index()\n",
    "keywords = keywords.melt(id_vars=[\"label\"], value_vars=[\"pro-vax\", \"neutral\", \"anti-vax\"])#.T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08533ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs = [\"#386fc2\", \"#83AFF2\"]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=\"variable\", y=\"value\", hue=\"label\", data=keywords, palette=clrs)\n",
    "ax = fig.gca()\n",
    "ax.set_title(\"TOPIC DISTRIBUTION IN USER TWEETS\", fontsize=24)\n",
    "ax.set_xlabel(\"Topic\", fontsize=21)\n",
    "ax.set_ylabel(\"Hashtags occurrences\", fontsize=21)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.legend(title=\"\", loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02c0a1",
   "metadata": {},
   "source": [
    "## TOPIC-USER PROJECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8e4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_retweet = nx.Graph()\n",
    "proj_like = nx.Graph()\n",
    "proj_mention = nx.Graph()\n",
    "proj_reply = nx.Graph()\n",
    "users = [x.split(\",\")[0] for x in open(\"dataset/verified_users.txt\", \"r\").read().split(\"\\n\")]\n",
    "proj_retweet.add_nodes_from(users)\n",
    "proj_like.add_nodes_from(users)\n",
    "proj_mention.add_nodes_from(users)\n",
    "proj_reply.add_nodes_from(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = json.load(open(\"dataset/verified_tweets.txt\", \"r\"))\n",
    "df = pd.DataFrame.from_records(tweets)\n",
    "df[\"screen_name\"] = df[\"user\"].apply(lambda x: x[\"screen_name\"])\n",
    "df[\"hashtags\"] = df[\"entities\"].apply(lambda x: [y[\"text\"] for y in x[\"hashtags\"]])\n",
    "df[\"full_text\"] = df[\"full_text\"].apply(lambda x: x.replace(\"“\", \"\").replace(\"”\", \"\").split(\" \"))\n",
    "df[\"full_text\"] = df[\"full_text\"].apply(lambda x: [y.translate(str.maketrans('', '', string.punctuation)).lower() for y in x])\n",
    "df[\"retweet_screen_name\"] = df[\"retweeted_status\"].apply(lambda x: x[\"user\"][\"screen_name\"] if not isinstance(x, float) else \"None\")\n",
    "\n",
    "likes_df = pd.read_csv(\"dataset/likes.csv\")\n",
    "likes_df[\"TweetText\"] = likes_df[\"TweetText\"].apply(lambda x: x.replace(\"“\", \"\").replace(\"”\", \"\").split(\" \"))\n",
    "likes_df[\"TweetText\"] = likes_df[\"TweetText\"].apply(lambda x: [y.translate(str.maketrans('', '', string.punctuation)).lower() for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8232f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for each projection to generate the all the networks\n",
    "projection = \"neutral\"\n",
    "keywords = {\"pro-vax\": provax, \"anti-vax\": novax, \"neutral\": neutral}\n",
    "\n",
    "for user in users:\n",
    "    user_tweets = df.loc[df[\"screen_name\"] == user].copy(deep=True)\n",
    "    user_tweets[\"fine\"] = user_tweets[\"full_text\"].apply(lambda x: len(set(x).intersection(keywords[projection])) > 0)\n",
    "    user_tweets = user_tweets.loc[user_tweets[\"fine\"] == True]\n",
    "    if len(user_tweets) > 0:\n",
    "        # replyto graph\n",
    "        for _, t in user_tweets.iterrows():\n",
    "            if t[\"in_reply_to_screen_name\"] in proj_reply.nodes:\n",
    "                a, b = t[\"user\"][\"screen_name\"], t[\"in_reply_to_screen_name\"]\n",
    "                if proj_reply.has_edge(a, b) or proj_reply.has_edge(b, a):\n",
    "                    proj_reply[a][b][\"weight\"] = proj_reply[a][b][\"weight\"] + 1\n",
    "                else:\n",
    "                    proj_reply.add_edge(a, b, weight=1)\n",
    "\n",
    "        # retweet graph\n",
    "        for _, t in user_tweets.iterrows():\n",
    "            a, b = t[\"screen_name\"], t[\"retweet_screen_name\"]\n",
    "            if a in proj_retweet.nodes and b in proj_retweet.nodes:\n",
    "                if proj_retweet.has_edge(a, b) or proj_retweet.has_edge(b, a):\n",
    "                    proj_retweet[a][b][\"weight\"] = proj_retweet[a][b][\"weight\"] + 1\n",
    "                else:\n",
    "                    proj_retweet.add_edge(a, b, weight=1)\n",
    "\n",
    "        # mention graph\n",
    "        for _, t in user_tweets.iterrows():\n",
    "            user_mentions = t[\"entities\"]['user_mentions']\n",
    "            mentions = [mention[\"screen_name\"] for mention in user_mentions if mention[\"screen_name\"] in users]\n",
    "            a = t[\"screen_name\"]\n",
    "            for b in mentions:\n",
    "                if a in proj_retweet.nodes and b in proj_retweet.nodes:\n",
    "                    if proj_mention.has_edge(a, b) or proj_mention.has_edge(b, a):\n",
    "                        proj_mention[a][b][\"weight\"] = proj_mention[a][b][\"weight\"] + 1\n",
    "                    else:\n",
    "                        proj_mention.add_edge(a, b, weight=1)\n",
    "\n",
    "        # like graph\n",
    "        like_user = likes_df.loc[likes_df[\"UsernameAutore\"] == user].copy(deep=True)\n",
    "        like_user[\"fine\"] = like_user[\"TweetText\"].apply(lambda x: len(set(x).intersection(keywords[projection])) > 0)\n",
    "        like_user = like_user.loc[like_user[\"fine\"] == True]\n",
    "        if len(like_user) > 0:\n",
    "            for _, t in like_user.iterrows():\n",
    "                a, b = t[\"UsernameAutore\"], t[\"UsernameUtenteLike\"]\n",
    "                if a in proj_retweet.nodes and b in proj_retweet.nodes:\n",
    "                    if proj_like.has_edge(a, b) or proj_like.has_edge(b, a):\n",
    "                        proj_like[a][b][\"weight\"] = proj_like[a][b][\"weight\"] + 1\n",
    "                    else:\n",
    "                        proj_like.add_edge(a, b, weight=1)\n",
    "\n",
    "\n",
    "proj_retweet.remove_edges_from(nx.selfloop_edges(proj_retweet))\n",
    "proj_reply.remove_edges_from(nx.selfloop_edges(proj_reply))\n",
    "proj_like.remove_edges_from(nx.selfloop_edges(proj_like))\n",
    "proj_mention.remove_edges_from(nx.selfloop_edges(proj_mention))\n",
    "\n",
    "nx.write_gexf(proj_retweet, base_path + \"proj-retweet-\" + projection + \".gexf\")\n",
    "nx.write_gexf(proj_reply, base_path + \"proj-reply-\" + projection + \".gexf\")\n",
    "nx.write_gexf(proj_like, base_path + \"proj-like-\" + projection + \".gexf\")\n",
    "nx.write_gexf(proj_mention, base_path + \"proj-mention-\" + projection + \".gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33497955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 20,\"\\nRETWEET\")\n",
    "graph_statistics(proj_retweet, need_plot=False)\n",
    "print(\"-\" * 20,\"\\nREPLY\")\n",
    "graph_statistics(proj_reply,need_plot=False)\n",
    "print(\"-\" * 20,\"\\nLIKE\")\n",
    "graph_statistics(proj_like,need_plot=False)\n",
    "print(\"-\" * 20,\"\\nMENTION\")\n",
    "graph_statistics(proj_mention,need_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0619e9",
   "metadata": {},
   "source": [
    "## ANALYSIS OF NETWORK PROJECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"pro-vax\", \"neutral\", \"anti-vax\"]\n",
    "networks = [\"retweet\", \"reply\", \"like\", \"mention\"]\n",
    "proj_graph = {k: {} for k in networks}\n",
    "base_url =  \"network/proj-\"\n",
    "stat = {k: {} for k in networks}\n",
    "for topic in topics:\n",
    "  for net in networks:\n",
    "    proj_graph[net][topic] = nx.read_gexf(base_url + net + \"-\" + topic + \".gexf\")\n",
    "    proj_graph[net][topic].remove_nodes_from(list(nx.isolates(proj_graph[net][topic])))\n",
    "    stat[net][topic] = {\"Nodes\": len(proj_graph[net][topic].nodes),\n",
    "                        \"Edges\": len(proj_graph[net][topic].edges),\n",
    "                        \"clustering coeff.\": nx.average_clustering(proj_graph[net][topic]),\n",
    "                        \"weight\": sum([x[2][\"weight\"] for x in proj_graph[net][topic].edges(data=True)]) / len(proj_graph[net][topic].edges)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#38705E\", \"#81FCD3\", \"#08A873\"]\n",
    "fig, ax = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "for i in range(len(networks)):\n",
    "    net = networks[i]\n",
    "    s = pd.DataFrame(stat[net]).T.reset_index().melt(id_vars=[\"index\"], value_vars=[\"Nodes\", \"Edges\"])\n",
    "    x, y = int((i) / 2), (i) % 2 \n",
    "    sns.barplot(x=\"variable\", y=\"value\", hue=\"index\", data=s, ax=ax[x, y], palette=colors)\n",
    "    if net.upper() == \"REPLY\":\n",
    "        ax[x, y].set_title(\"REPLY TO\", fontsize=24)\n",
    "    else:\n",
    "        ax[x, y].set_title(net.upper(), fontsize=24)\n",
    "    ax[x, y].set_xlabel(\"Network features\", fontsize=21)\n",
    "    ax[x, y].set_ylabel(\"Number of Nodes / Edges\", fontsize=21)\n",
    "    ax[x, y].tick_params(axis='both', which='major', labelsize=18)\n",
    "    ax[x, y].get_legend().remove()\n",
    "\n",
    "  # ax[x, y].set_yticks(fontsize=18)\n",
    "handles, labels = ax[0,0].get_legend_handles_labels()\n",
    "fig.legend(title=\"\", handles=handles,labels=labels, loc=\"upper center\", ncol=3,\n",
    "           fontsize=18, frameon=False)\n",
    "plt.subplots_adjust(hspace = .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5770ee",
   "metadata": {},
   "source": [
    "### ANALYZE INTERSECTIONS OF TOP USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8021b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_degree = {k: {} for k in topics}\n",
    "for topic in topics:\n",
    "    centralities = {}\n",
    "    all_users = []\n",
    "    for net in networks:\n",
    "        centralities[net] = {k: proj_graph[net][topic].degree(k) for k in proj_graph[net][topic].nodes}\n",
    "        all_users = all_users + list(centralities[net].keys())\n",
    "    all_users = list(set(all_users))\n",
    "    topic_degree = {}\n",
    "    for user in all_users:\n",
    "        if user:\n",
    "            topic_degree[user] = []\n",
    "            for c in centralities:\n",
    "                if user in centralities[c]:\n",
    "                    topic_degree[user].append(centralities[c][user])\n",
    "                else:\n",
    "                    topic_degree[user].append(0)\n",
    "            topic_degree[user] = statistics.mean(topic_degree[user])\n",
    "    multi_degree[topic] = {k: v for k, v in sorted(topic_degree.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800971e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top intersection\n",
    "print(list(multi_degree[\"pro-vax\"].keys())[:10])\n",
    "print(list(multi_degree[\"anti-vax\"].keys())[:10])\n",
    "print(list(multi_degree[\"neutral\"].keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [100, 200, 500, 800]\n",
    "heatmap = {}\n",
    "for n in ns:\n",
    "    k = \"Top-\" + str(n) + \" users\"\n",
    "    heatmap[k] = {}\n",
    "    heatmap[k][\"Common anti-vax and pro-vax\"] = len(set(list(multi_degree[\"pro-vax\"].keys())[:n]).intersection(list(multi_degree[\"anti-vax\"].keys())[:n])) / n * 100\n",
    "    heatmap[k][\"Common anti-vax and neutral\"] = len(set(list(multi_degree[\"neutral\"].keys())[:n]).intersection(list(multi_degree[\"anti-vax\"].keys())[:n])) / n * 100\n",
    "    heatmap[k][\"Common neutral and pro-vax\"] = len(set(list(multi_degree[\"pro-vax\"].keys())[:n]).intersection(list(multi_degree[\"neutral\"].keys())[:n])) / n * 100\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.heatmap(pd.DataFrame(heatmap), annot=True, cmap=\"Blues\", annot_kws={\"size\": 14})\n",
    "plt.tick_params(axis='both', which='major', labelsize=16, labelbottom = False, bottom=False, top = False, labeltop=True)\n",
    "for t in ax.texts: \n",
    "    t.set_text(t.get_text() + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a171b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study ego networks of the most influential users\n",
    "top_k = 200 \n",
    "n = 800\n",
    "multi_topic_ego = {k: {} for k in topics}\n",
    "single_topic_ego = {k: {\"Density\":0, \n",
    "                        \"Clustering coefficient\": 0, \n",
    "                        \"Nodes\": 0, \n",
    "                        \"Edges\": 0, \n",
    "                        \"Interactions\": 0,\n",
    "                        \"Users\": 0} for k in topics}\n",
    "for topic in topics:\n",
    "  top_users = list(multi_degree[topic].keys())[:n] # multilayer ego network analysis\n",
    "  # top_users = top_users_nolike # single networks analysis\n",
    "  for user in top_users:\n",
    "    ego_net = nx.Graph()\n",
    "    for net in networks:\n",
    "      if user in proj_graph[net][topic].nodes:\n",
    "        other_ego = nx.ego_graph(proj_graph[net][topic], user)\n",
    "        ego_net = nx.compose(ego_net, other_ego)\n",
    "        ego_net.remove_nodes_from(list(nx.isolates(ego_net)))\n",
    "        # update single stats\n",
    "        single_topic_ego[topic][\"Density\"] += nx.density(other_ego)\n",
    "        single_topic_ego[topic][\"Clustering coefficient\"] += nx.average_clustering(other_ego)\n",
    "        single_topic_ego[topic][\"Nodes\"] += len(other_ego.nodes)\n",
    "        single_topic_ego[topic][\"Edges\"] += len(other_ego.edges)\n",
    "        single_topic_ego[topic][\"Users\"] += 1\n",
    "        weights = other_ego.edges(data=True)\n",
    "        weights = [x[2][\"weight\"] for x in weights]\n",
    "        single_topic_ego[topic][\"Interactions\"] += sum(weights)\n",
    "    multi_topic_ego[topic][user] = ego_net\n",
    "\n",
    "# take mean of single stats\n",
    "single_stats = {}\n",
    "for topic in topics:\n",
    "  for k, v in single_topic_ego[topic].items():\n",
    "    if k != \"Users\":\n",
    "      single_topic_ego[topic][k] = v / single_topic_ego[topic][\"Users\"]\n",
    "  single_stats[topic] = pd.DataFrame.from_dict(single_topic_ego[topic], orient=\"index\").T\n",
    "  single_stats[topic][\"label\"] = topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad292442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot single networks ego analysis\n",
    "colors = [\"#38705E\", \"#81FCD3\", \"#08A873\"]\n",
    "data = pd.concat([single_stats[\"pro-vax\"], single_stats[\"neutral\"], single_stats[\"anti-vax\"]])\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "plot_data = data.reset_index().melt(id_vars=[\"label\"], value_vars=[\"Density\", \"Clustering coefficient\"])\n",
    "sns.barplot(x=\"variable\", y=\"value\", hue=\"label\", data=plot_data, ci=0.05, palette=colors)\n",
    "ax = fig.gca()\n",
    "ax.set_title(\"SINGLE EGO NETWORKS ANALYSIS\", fontsize=24)\n",
    "ax.set_xlabel(\"Network features\", fontsize=21)\n",
    "ax.set_ylabel(\"Density / Clustering\", fontsize=21)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylim((0, 1.))\n",
    "plt.legend(title=\"\", loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea18851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot single networks ego analysis\n",
    "colors = [\"#38705E\", \"#81FCD3\", \"#08A873\"]\n",
    "data = pd.concat([single_stats[\"pro-vax\"], single_stats[\"neutral\"], single_stats[\"anti-vax\"]])\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "plot_data = data.reset_index().melt(id_vars=[\"label\"], value_vars=[\"Nodes\", \"Edges\", \"Interactions\"])\n",
    "sns.barplot(x=\"variable\", y=\"value\", hue=\"label\", data=plot_data, ci=0.05, palette=colors)\n",
    "ax = fig.gca()\n",
    "ax.set_title(\"SINGLE EGO NETWORKS ANALYSIS\", fontsize=24)\n",
    "ax.set_xlabel(\"Network features\", fontsize=21)\n",
    "ax.set_ylabel(\"Number of Nodes / Edges / Interactions\", fontsize=21)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylim((0, 35))\n",
    "plt.legend(title=\"\", loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f209bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilayer plot\n",
    "stats = {k: {} for k in topics}\n",
    "threshold = 1\n",
    "for topic in topics:\n",
    "    info = []\n",
    "    top_users = list(multi_degree[topic].keys())[:n] # multilayer ego network analysis\n",
    "    for user in top_users: \n",
    "        if user in multi_topic_ego[topic] and len(multi_topic_ego[topic][user].edges) > threshold:\n",
    "            weights = multi_topic_ego[topic][user].edges(data=True)\n",
    "            weights = [x[2][\"weight\"] for x in weights]\n",
    "            info.append([\n",
    "                    nx.density(multi_topic_ego[topic][user]),\n",
    "                    nx.average_clustering(multi_topic_ego[topic][user]),\n",
    "                    len(multi_topic_ego[topic][user].nodes),\n",
    "                    len(multi_topic_ego[topic][user].edges),\n",
    "                    sum(weights)\n",
    "            ])\n",
    "\n",
    "    stats[topic] = pd.DataFrame(info, columns=[\"Density\", \"Clustering coefficient\", \"Nodes\", \"Edges\", \"Interactions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"pro-vax\"][\"label\"] = \"pro-vax\"\n",
    "stats[\"neutral\"][\"label\"] = \"neutral\"\n",
    "stats[\"anti-vax\"][\"label\"] = \"anti-vax\"\n",
    "colors = [\"#38705E\", \"#81FCD3\", \"#08A873\"]\n",
    "data = pd.concat([stats[\"pro-vax\"], stats[\"neutral\"], stats[\"anti-vax\"]])\n",
    "#data = data.groupby(\"label\").mean().reindex([\"provax\", \"neutral\", \"novax\"])\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "plot_data = data.reset_index().melt(id_vars=[\"label\"], value_vars=[\"Density\", \"Clustering coefficient\"])\n",
    "sns.barplot(x=\"variable\", y=\"value\", hue=\"label\", data=plot_data, ci=0.05, palette=colors)\n",
    "ax = fig.gca()\n",
    "ax.set_title(\"MULTILAYER EGO NETWORKS ANALYSIS\", fontsize=24)\n",
    "ax.set_xlabel(\"Network features\", fontsize=21)\n",
    "ax.set_ylabel(\"Density / Clustering\", fontsize=21)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylim((0, 1.))\n",
    "plt.legend(title=\"\", loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"pro-vax\"][\"label\"] = \"pro-vax\"\n",
    "stats[\"neutral\"][\"label\"] = \"neutral\"\n",
    "stats[\"anti-vax\"][\"label\"] = \"anti-vax\"\n",
    "\n",
    "data = pd.concat([stats[\"pro-vax\"], stats[\"neutral\"], stats[\"anti-vax\"]])\n",
    "#data = data.groupby(\"label\").mean().reindex([\"provax\", \"neutral\", \"novax\"])\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "plot_data = data.reset_index().melt(id_vars=[\"label\"], value_vars=[\"Nodes\", \"Edges\", \"Interactions\"])\n",
    "sns.barplot(x=\"variable\", y=\"value\", hue=\"label\", data=plot_data, ci=0.05, palette=colors)\n",
    "ax = fig.gca()\n",
    "ax.set_title(\"MULTILAYER EGO NETWORKS ANALYSIS\", fontsize=24)\n",
    "ax.set_xlabel(\"Network features\", fontsize=21)\n",
    "ax.set_ylabel(\"Number of Nodes / Edges / Interactions\", fontsize=21)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylim((0, 35))\n",
    "plt.legend(title=\"\", loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19ef70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage\n",
    "print(\"Anti-vax / Pro-Vax density:\", stats[\"anti-vax\"][\"Density\"].mean() / stats[\"pro-vax\"][\"Density\"].mean() - 1)\n",
    "print(\"Anti-vax / Pro-Vax clustering:\", stats[\"anti-vax\"][\"Clustering coefficient\"].mean() / stats[\"pro-vax\"][\"Clustering coefficient\"].mean() - 1)\n",
    "print(\"Anti-vax / Pro-Vax interactions:\", stats[\"anti-vax\"][\"Interactions\"].mean() / stats[\"pro-vax\"][\"Interactions\"].mean() - 1)\n",
    "\n",
    "#percentage\n",
    "print(\"Anti-vax / Neutral density:\", stats[\"anti-vax\"][\"Density\"].mean() / stats[\"neutral\"][\"Density\"].mean() - 1)\n",
    "print(\"Anti-vax / Neutral clustering:\", stats[\"anti-vax\"][\"Clustering coefficient\"].mean() / stats[\"neutral\"][\"Clustering coefficient\"].mean() - 1)\n",
    "print(\"Anti-vax / Neutral interactions:\", stats[\"anti-vax\"][\"Interactions\"].mean() / stats[\"neutral\"][\"Interactions\"].mean() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5020fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
